import os
import re
import xml.etree.ElementTree as ET
from collections import Counter
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import time
import matplotlib.pyplot as plt
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
import nltk

# ç¡®ä¿ä¸‹è½½å¿…è¦çš„NLTKèµ„æº
nltk.download('punkt', quiet=True)

# ----------------------------
# Transformeræ ¸å¿ƒç»„ä»¶å®ç°ï¼ˆç²¾ç®€éªŒè¯è¾“å‡ºï¼‰
# ----------------------------

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç å±‚"""
    def __init__(self, d_model, max_len=5000, dropout=0.1):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))
        
        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe)
        # ä»…ä¿ç•™åˆå§‹åŒ–æˆåŠŸæç¤º
        print(f"âœ… ä½ç½®ç¼–ç åˆå§‹åŒ–å®Œæˆï¼ˆd_model={d_model}ï¼‰")

    def forward(self, x):
        x = x + self.pe[:x.size(0)]
        return self.dropout(x)


class MultiHeadAttention(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶"""
    def __init__(self, d_model, num_heads, dropout=0.1):
        super().__init__()
        assert d_model % num_heads == 0, "d_modelå¿…é¡»èƒ½è¢«num_headsæ•´é™¤"
        
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        
        self.w_q = nn.Linear(d_model, d_model)
        self.w_k = nn.Linear(d_model, d_model)
        self.w_v = nn.Linear(d_model, d_model)
        self.w_o = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout)
        # ä»…ä¿ç•™åˆå§‹åŒ–æˆåŠŸæç¤º
        print(f"âœ… å¤šå¤´æ³¨æ„åŠ›åˆå§‹åŒ–å®Œæˆï¼ˆnum_heads={num_heads}ï¼‰")

    def forward(self, q, k, v, mask=None):
        batch_size = q.size(0)
        
        q = self.w_q(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        k = self.w_k(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        v = self.w_v(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        
        scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
            
        attn = torch.softmax(scores, dim=-1)
        attn = self.dropout(attn)
        
        output = torch.matmul(attn, v)
        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)
        
        return self.w_o(output), attn


class PositionWiseFeedForward(nn.Module):
    """ä½ç½®-wiseå‰é¦ˆç½‘ç»œ"""
    def __init__(self, d_model, dff, dropout=0.1):
        super().__init__()
        self.fc1 = nn.Linear(d_model, dff)
        self.fc2 = nn.Linear(dff, d_model)
        self.dropout = nn.Dropout(dropout)
        self.activation = nn.GELU()
        # ä»…ä¿ç•™åˆå§‹åŒ–æˆåŠŸæç¤º
        print(f"âœ… FFNåˆå§‹åŒ–å®Œæˆï¼ˆd_model={d_model} â†’ dff={dff}ï¼‰")

    def forward(self, x):
        x = self.fc1(x)
        x = self.activation(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x


class EncoderLayer(nn.Module):
    """ç¼–ç å™¨å±‚"""
    def __init__(self, d_model, num_heads, dff, dropout=0.1):
        super().__init__()
        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.feed_forward = PositionWiseFeedForward(d_model, dff, dropout)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)

    def forward(self, x, mask):
        attn_output, _ = self.self_attn(x, x, x, mask)
        x = self.norm1(x + self.dropout1(attn_output))
        
        ff_output = self.feed_forward(x)
        x = self.norm2(x + self.dropout2(ff_output))
        
        return x


class DecoderLayer(nn.Module):
    """è§£ç å™¨å±‚"""
    def __init__(self, d_model, num_heads, dff, dropout=0.1):
        super().__init__()
        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)
        self.feed_forward = PositionWiseFeedForward(d_model, dff, dropout)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.norm3 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)
        self.dropout3 = nn.Dropout(dropout)

    def forward(self, x, enc_output, self_mask, cross_mask):
        attn_output, _ = self.self_attn(x, x, x, self_mask)
        x = self.norm1(x + self.dropout1(attn_output))
        
        attn_output, _ = self.cross_attn(x, enc_output, enc_output, cross_mask)
        x = self.norm2(x + self.dropout2(attn_output))
        
        ff_output = self.feed_forward(x)
        x = self.norm3(x + self.dropout3(ff_output))
        
        return x


class Encoder(nn.Module):
    """å®Œæ•´ç¼–ç å™¨"""
    def __init__(self, input_vocab_size, d_model, num_layers, num_heads, dff, max_len=5000, dropout=0.1):
        super().__init__()
        self.d_model = d_model
        self.embedding = nn.Embedding(input_vocab_size, d_model)
        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout)
        self.layers = nn.ModuleList([
            EncoderLayer(d_model, num_heads, dff, dropout)
            for _ in range(num_layers)
        ])
        # ä»…ä¿ç•™æ ¸å¿ƒé…ç½®æç¤º
        print(f"âœ… ç¼–ç å™¨åˆå§‹åŒ–å®Œæˆï¼ˆnum_layers={num_layers}, vocab_size={input_vocab_size}ï¼‰")

    def forward(self, x, mask):
        seq_len = x.size(1)
        x = self.embedding(x)
        x = x * np.sqrt(self.d_model)
        x = self.pos_encoding(x.transpose(0, 1)).transpose(0, 1)
        
        for layer in self.layers:
            x = layer(x, mask)
            
        return x


class Decoder(nn.Module):
    """å®Œæ•´è§£ç å™¨"""
    def __init__(self, target_vocab_size, d_model, num_layers, num_heads, dff, max_len=5000, dropout=0.1):
        super().__init__()
        self.d_model = d_model
        self.embedding = nn.Embedding(target_vocab_size, d_model)
        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout)
        self.layers = nn.ModuleList([
            DecoderLayer(d_model, num_heads, dff, dropout)
            for _ in range(num_layers)
        ])
        # ä»…ä¿ç•™æ ¸å¿ƒé…ç½®æç¤º
        print(f"âœ… è§£ç å™¨åˆå§‹åŒ–å®Œæˆï¼ˆnum_layers={num_layers}, vocab_size={target_vocab_size}ï¼‰")

    def forward(self, x, enc_output, self_mask, cross_mask):
        seq_len = x.size(1)
        x = self.embedding(x)
        x = x * np.sqrt(self.d_model)
        x = self.pos_encoding(x.transpose(0, 1)).transpose(0, 1)
        
        for layer in self.layers:
            x = layer(x, enc_output, self_mask, cross_mask)
            
        return x


class Transformer(nn.Module):
    """å®Œæ•´Transformeræ¨¡å‹"""
    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_layers=6, 
                 num_heads=8, dff=2048, max_len=5000, dropout=0.1):
        super().__init__()
        self.encoder = Encoder(
            input_vocab_size=src_vocab_size,
            d_model=d_model,
            num_layers=num_layers,
            num_heads=num_heads,
            dff=dff,
            max_len=max_len,
            dropout=dropout
        )
        self.decoder = Decoder(
            target_vocab_size=tgt_vocab_size,
            d_model=d_model,
            num_layers=num_layers,
            num_heads=num_heads,
            dff=dff,
            max_len=max_len,
            dropout=dropout
        )
        self.final_layer = nn.Linear(d_model, tgt_vocab_size)
        # ä»…ä¿ç•™æ ¸å¿ƒé…ç½®æç¤º
        print(f"âœ… Transformeræ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆd_model={d_model}, num_layers={num_layers}, num_heads={num_heads}ï¼‰")

    def forward(self, src, tgt, src_mask, tgt_mask, cross_mask):
        enc_output = self.encoder(src, src_mask)
        dec_output = self.decoder(tgt, enc_output, tgt_mask, cross_mask)
        final_output = self.final_layer(dec_output)
        
        return final_output


# ----------------------------
# æ©ç å‡½æ•°ï¼ˆåˆ é™¤å†—ä½™å½¢çŠ¶æ‰“å°ï¼‰
# ----------------------------

def create_padding_mask(seq, pad_idx):
    """åˆ›å»ºå¡«å……æ©ç ï¼Œä¸è¾“å…¥åºåˆ—åŒè®¾å¤‡"""
    mask = (seq != pad_idx).unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, seq_len)
    return mask


def create_look_ahead_mask(seq_len, device):
    """åˆ›å»ºå‰ç»æ©ç ï¼Œå¼ºåˆ¶æŒ‡å®šè®¾å¤‡"""
    mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1).bool()
    return mask


def create_masks(src, tgt, src_pad_idx, tgt_pad_idx):
    """åˆ›å»ºæ‰€æœ‰æ©ç ï¼Œç¡®ä¿100%è®¾å¤‡ä¸€è‡´"""
    src_seq_len = src.size(1)
    tgt_seq_len = tgt.size(1)
    device = src.device  # ç»Ÿä¸€ä½¿ç”¨srcçš„è®¾å¤‡
    
    src_mask = create_padding_mask(src, src_pad_idx)
    cross_mask = create_padding_mask(src, src_pad_idx)
    tgt_pad_mask = create_padding_mask(tgt, tgt_pad_idx)
    tgt_look_ahead_mask = create_look_ahead_mask(tgt_seq_len, device).unsqueeze(0).unsqueeze(0)
    tgt_mask = tgt_pad_mask | tgt_look_ahead_mask
    
    
    
    return src_mask, tgt_mask, cross_mask


# ----------------------------
# æ•°æ®å¤„ç†ï¼ˆç²¾ç®€æ ·æœ¬å’Œç¼–ç æ‰“å°ï¼‰
# ----------------------------

def parse_train_file(file_path):
    """è§£æè®­ç»ƒæ–‡ä»¶ï¼Œæå–<doc>å†…éæ ‡ç­¾è¡Œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    sentences = []
    in_doc = False
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if line.startswith('<doc'):
            in_doc = True
            continue
        if line.startswith('</doc'):
            in_doc = False
            continue
        if in_doc and not line.startswith('<'):
            sentences.append(line)
    
    # ä»…ä¿ç•™æ•°é‡æç¤ºï¼Œåˆ é™¤å‰3æ¡æ ·æœ¬æ‰“å°
    print(f"âœ… ä» {os.path.basename(file_path)} æå–å‡º {len(sentences)} æ¡å¥å­")
    return sentences


def parse_xml_file(file_path):
    """è§£æXMLæ–‡ä»¶ï¼Œæå–<seg>æ ‡ç­¾æ–‡æœ¬"""
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
    except ET.ParseError as e:
        print(f"XMLè§£æé”™è¯¯ {file_path}: {e}")
        return []
    
    sentences = []
    for seg in root.iter('seg'):
        if seg.text:
            sentences.append(seg.text.strip())
    
    # ä»…ä¿ç•™æ•°é‡æç¤ºï¼Œåˆ é™¤å‰3æ¡æ ·æœ¬æ‰“å°
    print(f"âœ… ä» {os.path.basename(file_path)} æå–å‡º {len(sentences)} æ¡å¥å­")
    return sentences


def preprocess_text(text, lang='en'):
    """ä»…åŸºç¡€é¢„å¤„ç†ï¼šå°å†™+å»é™¤ç‰¹æ®Šå­—ç¬¦"""
    text = text.lower()
    if lang == 'de':
        text = re.sub(r"[^a-zA-Z0-9Ã¤Ã¶Ã¼ÃŸÃ Ã¢Ã¤Ã¨Ã©ÃªÃ«Ã®Ã¯Ã´Ã¶Ã¹Ã»Ã¼Ã¿Ã§\s]", " ", text)
    else:
        text = re.sub(r"[^a-zA-Z0-9Ã Ã¢Ã¤Ã¨Ã©ÃªÃ«Ã®Ã¯Ã´Ã¶Ã¹Ã»Ã¼Ã¿Ã§\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text


class Vocabulary:
    def __init__(self, max_size=10000):
        self.pad_token = '<pad>'
        self.sos_token = '<sos>'
        self.eos_token = '<eos>'
        self.unk_token = '<unk>'
        
        self.token2idx = {
            self.pad_token: 0,
            self.sos_token: 1,
            self.eos_token: 2,
            self.unk_token: 3
        }
        self.idx2token = {v: k for k, v in self.token2idx.items()}
        self.max_size = max_size
        self.word_count = Counter()
    
    def update(self, sentence):
        if not sentence:
            return
        tokens = sentence.split()
        self.word_count.update(tokens)
    
    def build(self):
        most_common = self.word_count.most_common(self.max_size - len(self.token2idx))
        for word, _ in most_common:
            idx = len(self.token2idx)
            self.token2idx[word] = idx
            self.idx2token[idx] = word
        
        # ä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œåˆ é™¤å†—ä½™æ‰“å°
        print(f"âœ… è¯æ±‡è¡¨æ„å»ºå®Œæˆï¼ˆå¤§å°={len(self.token2idx)}ï¼‰")
        print(f"ğŸ” é«˜é¢‘è¯Top5ï¼š{list(self.word_count.most_common(5))}")
    
    def encode(self, sentence, max_length=None):
        if not sentence:
            sentence = self.unk_token
        tokens = sentence.split()
        encoded = [self.token2idx[self.sos_token]]
        encoded += [self.token2idx.get(token, self.token2idx[self.unk_token]) for token in tokens]
        encoded += [self.token2idx[self.eos_token]]
        if max_length is not None:
            if len(encoded) > max_length:
                encoded = encoded[:max_length]
            else:
                encoded += [self.token2idx[self.pad_token]] * (max_length - len(encoded))
        # åˆ é™¤æ¯ä¸ªå¥å­çš„ç¼–ç æ‰“å°ï¼ˆé¿å…åˆ·å±ï¼‰
        return encoded
    
    def decode(self, indices):
        tokens = []
        for idx in indices:
            token = self.idx2token.get(idx, self.unk_token)
            if token == self.eos_token:
                break
            if token not in [self.pad_token, self.sos_token]:
                tokens.append(token)
        return ' '.join(tokens)
    
    def __len__(self):
        return len(self.token2idx)


class TranslationDataset(Dataset):
    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, max_len=50):
        self.src_sentences = src_sentences
        self.tgt_sentences = tgt_sentences
        self.src_vocab = src_vocab
        self.tgt_vocab = tgt_vocab
        self.max_len = max_len
        assert len(src_sentences) == len(tgt_sentences), "æº/ç›®æ ‡è¯­è¨€å¥å­æ•°ä¸åŒ¹é…"
    
    def __len__(self):
        return len(self.src_sentences)
    
    def __getitem__(self, idx):
        src_sentence = self.src_sentences[idx]
        tgt_sentence = self.tgt_sentences[idx]
        
        src_encoded = self.src_vocab.encode(src_sentence, self.max_len)
        tgt_encoded = self.tgt_vocab.encode(tgt_sentence, self.max_len)
        
        src_len = min(len(src_sentence.split()) + 2, self.max_len)
        tgt_len = min(len(tgt_sentence.split()) + 2, self.max_len)
        
        # åˆ é™¤æ¯10000ä¸ªæ ·æœ¬çš„æ‰“å°ï¼ˆé¿å…åˆ·å±ï¼‰
        return {
            'src': torch.tensor(src_encoded, dtype=torch.long),
            'tgt': torch.tensor(tgt_encoded, dtype=torch.long),
            'src_len': torch.tensor(src_len, dtype=torch.long),
            'tgt_len': torch.tensor(tgt_len, dtype=torch.long)
        }


def load_iwslt_dataset(data_dir, src_lang, tgt_lang, max_len=50, max_vocab_size=10000):
    """åŠ è½½æ•°æ®é›†"""
    prefix = f"{src_lang}-{tgt_lang}"
    train_src_path = os.path.join(data_dir, f'train.tags.{prefix}.{src_lang}')
    train_tgt_path = os.path.join(data_dir, f'train.tags.{prefix}.{tgt_lang}')
    dev_src_path = os.path.join(data_dir, f'IWSLT17.TED.dev2010.{prefix}.{src_lang}.xml')
    dev_tgt_path = os.path.join(data_dir, f'IWSLT17.TED.dev2010.{prefix}.{tgt_lang}.xml')
    test_src_path = os.path.join(data_dir, f'IWSLT17.TED.tst2010.{prefix}.{src_lang}.xml')
    test_tgt_path = os.path.join(data_dir, f'IWSLT17.TED.tst2010.{prefix}.{tgt_lang}.xml')
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    for path in [train_src_path, train_tgt_path, dev_src_path, dev_tgt_path, test_src_path, test_tgt_path]:
        if not os.path.exists(path):
            raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    
    # åŠ è½½åŸå§‹æ•°æ®
    print("\n=== åŠ è½½è®­ç»ƒæ•°æ® ===")
    train_src_raw = parse_train_file(train_src_path)
    train_tgt_raw = parse_train_file(train_tgt_path)
    print("\n=== åŠ è½½å¼€å‘æ•°æ® ===")
    dev_src_raw = parse_xml_file(dev_src_path)
    dev_tgt_raw = parse_xml_file(dev_tgt_path)
    print("\n=== åŠ è½½æµ‹è¯•æ•°æ® ===")
    test_src_raw = parse_xml_file(test_src_path)
    test_tgt_raw = parse_xml_file(test_tgt_path)
    
    # åŸºç¡€é¢„å¤„ç†
    def basic_preprocess(src_sents, tgt_sents, src_lang, tgt_lang):
        processed_src = [preprocess_text(sent, src_lang) for sent in src_sents]
        processed_tgt = [preprocess_text(sent, tgt_lang) for sent in tgt_sents]
        return processed_src, processed_tgt
    
    print("\n=== åŸºç¡€é¢„å¤„ç† ===")
    train_src, train_tgt = basic_preprocess(train_src_raw, train_tgt_raw, src_lang, tgt_lang)
    dev_src, dev_tgt = basic_preprocess(dev_src_raw, dev_tgt_raw, src_lang, tgt_lang)
    test_src, test_tgt = basic_preprocess(test_src_raw, test_tgt_raw, src_lang, tgt_lang)
    
    # æ•°æ®é‡éªŒè¯ï¼ˆä¿ç•™æ ¸å¿ƒï¼‰
    print(f"\næ•°æ®é‡éªŒè¯:")
    print(f"è®­ç»ƒé›†: æº{len(train_src)}æ¡ | ç›®æ ‡{len(train_tgt)}æ¡")
    print(f"å¼€å‘é›†: æº{len(dev_src)}æ¡ | ç›®æ ‡{len(dev_tgt)}æ¡")
    print(f"æµ‹è¯•é›†: æº{len(test_src)}æ¡ | ç›®æ ‡{len(test_tgt)}æ¡")
    
    # æ„å»ºè¯æ±‡è¡¨
    print("\n=== æ„å»ºè¯æ±‡è¡¨ ===")
    src_vocab = Vocabulary(max_size=max_vocab_size)
    tgt_vocab = Vocabulary(max_size=max_vocab_size)
    print(f"ğŸ” æ­£åœ¨æ›´æ–°æºè¯­è¨€è¯æ±‡è¡¨...")
    for sent in train_src[:10000]:  # å…ˆæ›´æ–°å‰10000æ¡åŠ é€ŸéªŒè¯
        src_vocab.update(sent)
    print(f"ğŸ” æ­£åœ¨æ›´æ–°ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨...")
    for sent in train_tgt[:10000]:
        tgt_vocab.update(sent)
    src_vocab.build()
    tgt_vocab.build()
    
    print(f"æºè¯­è¨€è¯æ±‡è¡¨å¤§å°: {len(src_vocab)}")
    print(f"ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°: {len(tgt_vocab)}")
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = TranslationDataset(train_src, train_tgt, src_vocab, tgt_vocab, max_len)
    dev_dataset = TranslationDataset(dev_src, dev_tgt, src_vocab, tgt_vocab, max_len)
    test_dataset = TranslationDataset(test_src, test_tgt, src_vocab, tgt_vocab, max_len)
    
    print(f"âœ… æ•°æ®é›†åˆ›å»ºå®Œæˆï¼ˆtrain={len(train_dataset)}, dev={len(dev_dataset)}, test={len(test_dataset)}ï¼‰")
    return {
        'train': train_dataset,
        'dev': dev_dataset,
        'test': test_dataset,
        'src_vocab': src_vocab,
        'tgt_vocab': tgt_vocab
    }


# ----------------------------
# è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°ï¼ˆç²¾ç®€æ‰¹æ¬¡æ‰“å°ï¼‰
# ----------------------------

def train_model(
    model, train_loader, dev_loader, src_vocab, tgt_vocab,
    epochs=10, lr=1e-4, device='cuda', model_save_path='transformer_iwslt_en_de.pth'
):
    if torch.cuda.device_count() > 1:
        print(f"âš ï¸  æ£€æµ‹åˆ° {torch.cuda.device_count()} å—GPUï¼Œä½¿ç”¨DataParallelåŠ é€Ÿ")
        model = nn.DataParallel(model)
    
    pad_idx = src_vocab.token2idx[src_vocab.pad_token]
    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)
    
    model.to(device)
    train_losses = []
    dev_losses = []
    best_bleu = 0.0
    
    for epoch in range(epochs):
        start_time = time.time()
        model.train()
        train_loss = 0.0
        
        print(f"\n=== Epoch {epoch+1}/{epochs} è®­ç»ƒå¼€å§‹ ===")
        for batch_idx, batch in enumerate(train_loader):
            # æ‰€æœ‰æ•°æ®ç§»åˆ°è®¾å¤‡
            src = batch['src'].to(device, non_blocking=True)
            tgt = batch['tgt'].to(device, non_blocking=True)
            
            tgt_input = tgt[:, :-1]
            tgt_output = tgt[:, 1:]
            
            
            # åˆ›å»ºæ©ç 
            src_mask, tgt_mask, cross_mask = create_masks(
                src, tgt_input, 
                src_vocab.token2idx[src_vocab.pad_token],
                tgt_vocab.token2idx[tgt_vocab.pad_token]
            )
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            logits = model(src, tgt_input, src_mask, tgt_mask, cross_mask)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(
                logits.reshape(-1, logits.size(-1)),
                tgt_output.reshape(-1)
            )
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item() * src.size(0)
            

        
        # å¹³å‡æŸå¤±
        train_loss /= len(train_loader.dataset)
        train_losses.append(train_loss)
        
        # å¼€å‘é›†è¯„ä¼°
        dev_loss, dev_bleu = evaluate(model, dev_loader, src_vocab, tgt_vocab, criterion, device)
        dev_losses.append(dev_loss)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(dev_loss)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if dev_bleu > best_bleu:
            best_bleu = dev_bleu
            if torch.cuda.device_count() > 1:
                torch.save(model.module.state_dict(), model_save_path)
            else:
                torch.save(model.state_dict(), model_save_path)
            print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆBLEU: {best_bleu:.4f}ï¼‰")
        
        # æ‰“å°æ—¥å¿—
        epoch_time = time.time() - start_time
        print(f"\nEpoch {epoch+1}/{epochs} ç»“æŸ")
        print(f"train_loss: {train_loss:.4f} | val_loss: {dev_loss:.4f} | BLEU: {dev_bleu:.4f} | æ—¶é—´: {epoch_time:.2f}ç§’")
    
    plt.plot(train_losses, label='train_loss')
    plt.plot(dev_losses, label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('loss')
    plt.legend()
    plt.savefig('loss_curve_en_de.png')
    plt.close()
    print(f"âœ… æŸå¤±æ›²çº¿å·²ä¿å­˜ä¸º loss_curve_en_de.png")
    
    return model


def evaluate(model, dataloader, src_vocab, tgt_vocab, criterion, device):
    model.eval()
    total_loss = 0.0
    all_references = []
    all_hypotheses = []
    smoothing = SmoothingFunction().method4
    pad_idx = src_vocab.token2idx[src_vocab.pad_token]
    
    print("\n=== å¼€å§‹è¯„ä¼° ===")
    with torch.no_grad():
        for batch_idx, batch in enumerate(dataloader):
            src = batch['src'].to(device, non_blocking=True)
            tgt = batch['tgt'].to(device, non_blocking=True)
            
            tgt_input = tgt[:, :-1]
            tgt_output = tgt[:, 1:]
            
            # ä»…ç¬¬1æ‰¹æ¬¡æ‰“å°å½¢çŠ¶
            if batch_idx == 0:
                print(f"ğŸ” è¯„ä¼°ç¬¬1æ‰¹æ¬¡å½¢çŠ¶ï¼šsrc={src.shape}, tgt_output={tgt_output.shape}")
            
            src_mask, tgt_mask, cross_mask = create_masks(
                src, tgt_input, 
                src_vocab.token2idx[src_vocab.pad_token],
                tgt_vocab.token2idx[tgt_vocab.pad_token]
            )
            
            logits = model(src, tgt_input, src_mask, tgt_mask, cross_mask)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(
                logits.reshape(-1, logits.size(-1)),
                tgt_output.reshape(-1)
            )
            total_loss += loss.item() * src.size(0)
            
            # æ”¶é›†é¢„æµ‹ç»“æœ
            preds = torch.argmax(logits, dim=-1)
            # ä»…ç¬¬1æ‰¹æ¬¡æ‰“å°å‰1ä¸ªæ ·æœ¬å¯¹æ¯”
            if batch_idx == 0:
                reference = tgt_vocab.decode(tgt_output[0].cpu().numpy())
                hypothesis = tgt_vocab.decode(preds[0].cpu().numpy())
                print(f"ğŸ” è¯„ä¼°æ ·æœ¬ç¤ºä¾‹ï¼š")
                print(f"  å‚è€ƒï¼š{reference}")
                print(f"  é¢„æµ‹ï¼š{hypothesis}")
            
            for i in range(src.size(0)):
                reference = tgt_vocab.decode(tgt_output[i].cpu().numpy())
                all_references.append([reference.split()])
                hypothesis = tgt_vocab.decode(preds[i].cpu().numpy())
                all_hypotheses.append(hypothesis.split())
    
    avg_loss = total_loss / len(dataloader.dataset)
    bleu_score = sum(sentence_bleu(ref, hyp, smoothing_function=smoothing) 
                     for ref, hyp in zip(all_references, all_hypotheses)) / len(all_references)
    
    print(f"âœ… è¯„ä¼°å®Œæˆï¼ˆå¹³å‡æŸå¤±={avg_loss:.4f}, BLEU={bleu_score*100:.4f}ï¼‰")
    return avg_loss, bleu_score * 100


# ----------------------------
# æŸæœç´¢è§£ç ï¼ˆç²¾ç®€ä¸­é—´æ­¥éª¤æ‰“å°ï¼‰
# ----------------------------

def translate_beam_search(
    model, sentence, src_vocab, tgt_vocab, 
    src_lang='en', tgt_lang='de', max_len=50, device='cuda',
    beam_size=5, repeat_penalty=1.2, temperature=0.7
):
    """ä½¿ç”¨æŸæœç´¢è§£ç ï¼Œé¿å…é‡å¤ç¿»è¯‘ï¼ˆç²¾ç®€è¾“å‡ºï¼‰"""
    model.eval()
    if hasattr(model, 'module'):
        model = model.module  # å¤šGPUæ¨¡å‹é€‚é…
    
    # é¢„å¤„ç†è¾“å…¥å¥å­
    processed = preprocess_text(sentence, src_lang)
    print(f"ğŸ” ç¿»è¯‘è¾“å…¥ï¼š{sentence} â†’ é¢„å¤„ç†åï¼š{processed}")
    
    src_encoded = src_vocab.encode(processed, max_len)
    src_tensor = torch.tensor([src_encoded], dtype=torch.long).to(device)
    src_mask = create_padding_mask(src_tensor, src_vocab.token2idx[src_vocab.pad_token])
    
    # æå‰è®¡ç®—ç¼–ç å™¨è¾“å‡º
    with torch.no_grad():
        enc_output = model.encoder(src_tensor, src_mask)
    
    # æŸåˆå§‹åŒ–
    beams = [([tgt_vocab.token2idx[tgt_vocab.sos_token]], 0.0, 1)]
    finished = []
    
    with torch.no_grad():
        for _ in range(max_len - 1):
            if not beams or len(finished) >= beam_size:
                break
            
            new_beams = []
            for seq, score, length in beams:
                if seq[-1] == tgt_vocab.token2idx[tgt_vocab.eos_token]:
                    finished.append((seq, score / length))
                    continue
                
                tgt_tensor = torch.tensor([seq], dtype=torch.long).to(device)
                tgt_mask = create_look_ahead_mask(len(seq), device).unsqueeze(0)
                cross_mask = src_mask
                
                dec_output = model.decoder(tgt_tensor, enc_output, tgt_mask, cross_mask)
                logits = model.final_layer(dec_output)
                
                next_token_logits = logits[:, -1, :] / temperature
                next_token_probs = torch.softmax(next_token_logits, dim=-1)
                next_token_log_probs = torch.log(next_token_probs)
                
                # é‡å¤æƒ©ç½š
                for idx in seq:
                    if idx != tgt_vocab.token2idx[tgt_vocab.sos_token]:
                        next_token_log_probs[0][idx] -= np.log(repeat_penalty)
                
                top_log_probs, top_indices = next_token_log_probs.topk(beam_size)
                for log_prob, idx in zip(top_log_probs[0], top_indices[0]):
                    new_seq = seq.copy()
                    new_seq.append(idx.item())
                    new_score = score + log_prob.item()
                    new_beams.append((new_seq, new_score, length + 1))
            
            # ä¿ç•™å¾—åˆ†æœ€é«˜çš„beam_sizeä¸ªæŸ
            new_beams.sort(key=lambda x: x[1] / x[2], reverse=True)
            beams = new_beams[:beam_size]
    
    # åˆå¹¶å®Œæˆçš„åºåˆ—å’Œæœªå®Œæˆçš„æŸ
    finished.extend([(seq, score / length) for seq, score, length in beams])
    finished.sort(key=lambda x: x[1], reverse=True)
    best_seq = finished[0][0] if finished else beams[0][0]
    best_translated = tgt_vocab.decode(best_seq)
    
    # ä»…æ‰“å°æœ€ç»ˆå€™é€‰ï¼ˆå‰2ä¸ªï¼‰
    print(f"ğŸ” è§£ç å®Œæˆï¼Œæœ€ä½³ç¿»è¯‘ï¼š{best_translated}")
    if len(finished) > 1:
        second_translated = tgt_vocab.decode(finished[1][0])
        print(f"ğŸ” å€™é€‰ç¿»è¯‘2ï¼š{second_translated}")
    
    return best_translated


# ----------------------------
# ä¸»å‡½æ•°ï¼ˆä¿æŒæ ¸å¿ƒé…ç½®ï¼‰
# ----------------------------

def main():
    # é…ç½®å‚æ•°
    data_dir = "./iwslt17_data"
    src_lang = "en"
    tgt_lang = "de"
    max_len = 50
    max_vocab_size = 20000
    batch_size = 64
    d_model = 512
    num_layers = 4
    num_heads = 8
    dff = 2048
    epochs = 30  # æ”¹ä¸º30ä¸ªepochç¡®ä¿æ”¶æ•›
    lr = 1e-4
    model_save_path = "transformer_iwslt_en_de_4090.pth"
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"===== åˆå§‹åŒ–é…ç½® =====")
    print(f"ä½¿ç”¨è®¾å¤‡: {device} | GPUæ•°é‡: {torch.cuda.device_count()} å—")
    print(f"è®­ç»ƒè¯­è¨€å¯¹: {src_lang} â†’ {tgt_lang} | æ‰¹æ¬¡å¤§å°: {batch_size} | è®­ç»ƒè½®æ¬¡: {epochs}")
    print(f"======================\n")
    
    # åŠ è½½æ•°æ®é›†
    print("\n=== åŠ è½½IWSLT 2017æ•°æ®é›† ===")
    try:
        dataset = load_iwslt_dataset(
            data_dir, src_lang, tgt_lang, 
            max_len=max_len, 
            max_vocab_size=max_vocab_size
        )
    except FileNotFoundError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        dataset['train'], 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=8,
        pin_memory=True,
        drop_last=True
    )
    dev_loader = DataLoader(
        dataset['dev'], 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=8,
        pin_memory=True
    )
    test_loader = DataLoader(
        dataset['test'], 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=8,
        pin_memory=True
    )
    
    # æ‰“å°æ•°æ®åŠ è½½å™¨ä¿¡æ¯
    print(f"\n=== æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ ===")
    print(f"è®­ç»ƒé›†æ‰¹æ¬¡æ•°é‡ï¼š{len(train_loader)} | å¼€å‘é›†ï¼š{len(dev_loader)} | æµ‹è¯•é›†ï¼š{len(test_loader)}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("\n=== åˆå§‹åŒ–Transformeræ¨¡å‹ ===")
    model = Transformer(
        src_vocab_size=len(dataset['src_vocab']),
        tgt_vocab_size=len(dataset['tgt_vocab']),
        d_model=d_model,
        num_layers=num_layers,
        num_heads=num_heads,
        dff=dff,
        max_len=max_len,
        dropout=0.1
    )
    
    # æ‰“å°æ¨¡å‹æ€»å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    print(f"\nâœ… æ¨¡å‹æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")
    
    # è®­ç»ƒæ¨¡å‹
    print("\n=== å¼€å§‹è®­ç»ƒ ===")
    model = train_model(
        model, train_loader, dev_loader,
        dataset['src_vocab'], dataset['tgt_vocab'],
        epochs=epochs, lr=lr, device=device,
        model_save_path=model_save_path
    )
    
    # æµ‹è¯•é›†è¯„ä¼°
    print("\n=== æµ‹è¯•é›†è¯„ä¼° ===")
    criterion = nn.CrossEntropyLoss(ignore_index=dataset['src_vocab'].token2idx[dataset['src_vocab'].pad_token]).to(device)
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if torch.cuda.device_count() > 1:
        model.module.load_state_dict(torch.load(model_save_path, map_location=device, weights_only=True))
    else:
        model.load_state_dict(torch.load(model_save_path, map_location=device, weights_only=True))
    print(f"âœ… å·²åŠ è½½æœ€ä½³æ¨¡å‹ï¼š{model_save_path}")
    test_loss, test_bleu = evaluate(model, test_loader, dataset['src_vocab'], dataset['tgt_vocab'], criterion, device)
    print(f"æµ‹è¯•æŸå¤±: {test_loss:.4f} | æµ‹è¯•BLEUåˆ†æ•°: {test_bleu:.4f}")
    
    # æµ‹è¯•é›†ç¬¬ä¸€å¥ç¿»è¯‘éªŒè¯
    print("\n=== æµ‹è¯•é›†ç¬¬ä¸€å¥ç¿»è¯‘éªŒè¯ ===")
    test_src_sentence = dataset['test'].src_sentences[0]
    test_tgt_reference = dataset['test'].tgt_sentences[0]
    
    translated = translate_beam_search(
        model=model,
        sentence=test_src_sentence,
        src_vocab=dataset['src_vocab'],
        tgt_vocab=dataset['tgt_vocab'],
        src_lang=src_lang,
        tgt_lang=tgt_lang,
        max_len=max_len,
        device=device,
        beam_size=5,
        repeat_penalty=1.5,
        temperature=0.8
    )
    
    print(f"\nğŸ“Š æœ€ç»ˆç¿»è¯‘å¯¹æ¯”ï¼š")
    print(f"æµ‹è¯•é›†åŸæ–‡: {test_src_sentence}")
    print(f"æ¨¡å‹ç¿»è¯‘: {translated}")
    print(f"å‚è€ƒè¯‘æ–‡: {test_tgt_reference}")
    print("-" * 80)
    
    # ç¤ºä¾‹å¥å­ç¿»è¯‘
    print("\n=== ç¤ºä¾‹å¥å­ç¿»è¯‘ ===")
    sample_srcs = [
        "Climate change is a serious global problem.",
        "Technology can help solve many challenges.",
        "We need to protect our environment for future generations."
    ]
    for src in sample_srcs:
        print(f"\nğŸ“Œ è¾“å…¥ï¼š{src}")
        translated = translate_beam_search(
            model=model, sentence=src, 
            src_vocab=dataset['src_vocab'], tgt_vocab=dataset['tgt_vocab'],
            device=device, beam_size=5, repeat_penalty=1.5, temperature=0.8
        )
        print(f"ğŸ“Œ è¾“å‡ºï¼š{translated}")
        print("-" * 80)


if __name__ == "__main__":
    main()